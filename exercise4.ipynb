{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZRozoIQh6OjxNTB4vTkI3W5byznzqnmX","authorship_tag":"ABX9TyOhQP1om97KGMTbwwUN5MDu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Day 4 Exercise: Data Warehousing, Data Modeling & DevOps/CICD üèóÔ∏è\n","\n","#### Objective\n","This exercise focuses on the principles of data warehousing and analytical data modeling. You will design a Star Schema for our fraud analytics use case and conceptualize how to build and deploy the data pipeline using DevOps and CI/CD practices.\n","\n","#### Scenario\n","The fraud detection rules are now implemented in PySpark. The next step is to store the enriched transaction data and fraud flags in a structured, optimized way for business intelligence (BI) and analytics. You need to design a data model that allows analysts to easily query and build dashboards on fraudulent activities. You also need to think about how to automate the deployment of your data pipeline.\n","\n","#### Data to Use üìä\n","You will use the conceptual output from the Day 3 exercise: a PySpark DataFrame (`sdf_final_transactions`) containing enriched transaction data along with the boolean fraud flags (`is_fraudulent_rule1`, `is_fraudulent_rule2`).\n","\n","---\n","\n","### Part 1: Data Modeling for Fraud Analytics (Conceptual) ‚≠ê\n","\n","#### 1.1 Design a Star Schema\n","Based on the available data, design a **Star Schema** to model the data for analytical querying. Define the tables, columns, data types, and relationships.\n","\n","* **Fact Table**: `fact_transactions`\n","    * What are the measures (the quantitative values) in this table?\n","    * What are the foreign keys that will link to the dimension tables?\n","    * Define all columns, their data types (e.g., INTEGER, DECIMAL, VARCHAR, DATETIME, BOOLEAN), and their purpose.\n","\n","* **Dimension Tables**:\n","    * **`dim_customer`**:\n","        * How would you populate this table?\n","        * Define its columns, including a surrogate key.\n","    * **`dim_date`**:\n","        * Why is a separate date dimension useful?\n","        * What are some useful attributes this table would contain (e.g., day, week, month, quarter, year, day_of_week)?\n","        * Define its columns.\n","    * **`dim_location`** (Optional, but recommended):\n","        * How could you create a location dimension from the `ip_address`? (Conceptually - e.g., using a Geo-IP lookup service).\n","        * What columns would it have?\n","\n","#### 1.2 Slowly Changing Dimensions (SCD)\n","* In Day 2, we discussed SCD Type 2 for `customer_tier`. Now, provide a more detailed explanation.\n","* **Task**: Illustrate how you would update the `dim_customer` table if \"Alice Smith\" (customer_id 'C101') was upgraded from \"Gold\" to \"Platinum\" tier on `2024-07-18`.\n","* Show the state of the `dim_customer` table **before** and **after** the change, including the necessary columns to handle SCD Type 2 (e.g., `customer_sk`, `customer_id`, `tier`, `start_date`, `end_date`, `is_current`).\n","\n","---\n","\n","### Part 2: DevOps & CI/CD for Data Pipelines (Conceptual) ü§ñ\n","\n","#### 2.1 Version Control with Git\n","* Describe how you would structure your project in a Git repository. What would be the key folders and files? (e.g., `/src` for code, `/tests` for unit tests, `/notebooks` for exploration, `requirements.txt`, etc.).\n","* Explain the purpose of a `.gitignore` file in this project. What are some specific files or directories you would add to it?\n","\n","#### 2.2 Continuous Integration (CI)\n","* What is the primary goal of Continuous Integration for this data engineering project?\n","* Describe a simple CI pipeline for your PySpark fraud detection script. What are the key stages or steps?\n","    * **Hint**: Think about what should happen automatically when a developer pushes a change to a feature branch. (e.g., Trigger, Linting, Unit Testing, Packaging).\n","\n","#### 2.3 Continuous Deployment/Delivery (CD)\n","* What is the difference between Continuous Delivery and Continuous Deployment in the context of this project?\n","* Describe a conceptual CD pipeline that takes the tested PySpark application from the CI pipeline and deploys it to your Azure Databricks environment. What are the key stages?\n","    * **Hint**: Think about environments (Dev, Staging, Prod), approvals, and the actual deployment steps."],"metadata":{"id":"1zqEc9k7BWUw"}},{"cell_type":"markdown","source":["SOLUTION"],"metadata":{"id":"bOMkgVrO6Clm"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"FraudDataLoading\").getOrCreate()\n","\n","# Define the file path\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/fraud_detection_exercise/sdf_final_transaction.csv/part-00000-b3362811-915c-4425-8025-3a497ac441f9-c000.csv\"\n","\n","# Load the dataset into a DataFrame\n","# We assume the CSV has a header and infer the schema\n","sdf_final_transactions = spark.read.csv(file_path, header=True, inferSchema=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"j6HkTs6zejng","executionInfo":{"status":"ok","timestamp":1752941986233,"user_tz":-120,"elapsed":21435,"user":{"displayName":"Roberto Cerrone","userId":"14489044185171455121"}},"outputId":"1b56527b-b1aa-418a-ef6e-2392c49aadd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame Schema:\n","root\n"," |-- transaction_id: string (nullable = true)\n"," |-- customer_id: string (nullable = true)\n"," |-- amount: double (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n"," |-- currency: string (nullable = true)\n"," |-- ip_address: string (nullable = true)\n"," |-- transaction_hour: integer (nullable = true)\n"," |-- customer_name: string (nullable = true)\n"," |-- customer_email: string (nullable = true)\n"," |-- registration_date: date (nullable = true)\n"," |-- customer_tier: string (nullable = true)\n"," |-- last_login_date: string (nullable = true)\n"," |-- is_fraudulent_rule1: boolean (nullable = true)\n"," |-- timestamp_to_date: date (nullable = true)\n"," |-- is_fraudulent_rule1_spark: boolean (nullable = true)\n"," |-- prev_ip_address: string (nullable = true)\n"," |-- transaction_count_10min: integer (nullable = true)\n"," |-- is_fraudulent_rule2: boolean (nullable = true)\n"," |-- is_fraudulent_combined: boolean (nullable = true)\n","\n","\n","DataFrame Records:\n","+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-----------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n","|transaction_id|customer_id|amount|          timestamp|currency|  ip_address|transaction_hour|customer_name|   customer_email|registration_date|customer_tier|last_login_date|is_fraudulent_rule1|timestamp_to_date|is_fraudulent_rule1_spark|prev_ip_address|transaction_count_10min|is_fraudulent_rule2|is_fraudulent_combined|\n","+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-----------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n","|         TX001|       C101|150.75|2024-07-16 10:00:00|     USD|192.168.1.10|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX003|       C101| 50.25|2024-07-16 10:02:00|     USD|192.168.1.10|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      2|              false|                 false|\n","|         TX007|       C101|  10.0|2024-07-16 10:06:00|     USD|192.168.1.14|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      3|              false|                 false|\n","|         TX011|       C101| 500.0|2024-07-16 10:10:00|     USD|192.168.1.10|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.14|                      4|               true|                  true|\n","|         TX002|       C102|  25.0|2024-07-16 10:01:30|     USD|192.168.1.11|              10|  Bob Johnson|  bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-----------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","source":["\n","# Print the schema\n","print(\"DataFrame Schema:\")\n","sdf_final_transactions.printSchema()\n","\n","# Show some records\n","print(\"\\nDataFrame Records:\")\n","sdf_final_transactions.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"j7uDZFRbfE1A","executionInfo":{"status":"ok","timestamp":1752942011644,"user_tz":-120,"elapsed":353,"user":{"displayName":"Roberto Cerrone","userId":"14489044185171455121"}},"outputId":"84190d70-fdef-4198-c42d-a8edd0557c79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame Schema:\n","root\n"," |-- transaction_id: string (nullable = true)\n"," |-- customer_id: string (nullable = true)\n"," |-- amount: double (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n"," |-- currency: string (nullable = true)\n"," |-- ip_address: string (nullable = true)\n"," |-- transaction_hour: integer (nullable = true)\n"," |-- customer_name: string (nullable = true)\n"," |-- customer_email: string (nullable = true)\n"," |-- registration_date: date (nullable = true)\n"," |-- customer_tier: string (nullable = true)\n"," |-- last_login_date: string (nullable = true)\n"," |-- is_fraudulent_rule1: boolean (nullable = true)\n"," |-- timestamp_to_date: date (nullable = true)\n"," |-- is_fraudulent_rule1_spark: boolean (nullable = true)\n"," |-- prev_ip_address: string (nullable = true)\n"," |-- transaction_count_10min: integer (nullable = true)\n"," |-- is_fraudulent_rule2: boolean (nullable = true)\n"," |-- is_fraudulent_combined: boolean (nullable = true)\n","\n","\n","DataFrame Records:\n","+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-------------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n","|transaction_id|customer_id|amount|          timestamp|currency|  ip_address|transaction_hour|customer_name|     customer_email|registration_date|customer_tier|last_login_date|is_fraudulent_rule1|timestamp_to_date|is_fraudulent_rule1_spark|prev_ip_address|transaction_count_10min|is_fraudulent_rule2|is_fraudulent_combined|\n","+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-------------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n","|         TX001|       C101|150.75|2024-07-16 10:00:00|     USD|192.168.1.10|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX003|       C101| 50.25|2024-07-16 10:02:00|     USD|192.168.1.10|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      2|              false|                 false|\n","|         TX007|       C101|  10.0|2024-07-16 10:06:00|     USD|192.168.1.14|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      3|              false|                 false|\n","|         TX011|       C101| 500.0|2024-07-16 10:10:00|     USD|192.168.1.10|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.14|                      4|               true|                  true|\n","|         TX002|       C102|  25.0|2024-07-16 10:01:30|     USD|192.168.1.11|              10|  Bob Johnson|    bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX005|       C102|  75.5|2024-07-16 10:04:00|     USD|192.168.1.11|              10|  Bob Johnson|    bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|   192.168.1.11|                      2|              false|                 false|\n","|         TX009|       C102| 200.0|2024-07-16 10:08:00|     USD|192.168.1.11|              10|  Bob Johnson|    bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|   192.168.1.11|                      3|              false|                 false|\n","|         TX004|       C103|1200.0|2024-07-16 10:03:15|     EUR|192.168.1.12|              10|Charlie Brown|charlie@example.com|       2023-11-20|       Bronze|     2024-07-14|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX006|       C104| 300.0|2024-07-16 10:05:00|     USD|192.168.1.13|              10| Diana Prince|  diana@example.com|       2024-07-10|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX008|       C105|   0.0|2024-07-16 10:07:00|     USD|192.168.1.15|              10|    Eve Adams|    eve@example.com|       2023-05-01|         Gold|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX010|       C106|  45.0|2024-07-16 10:09:00|     USD|192.168.1.16|              10|  Frank White|  frank@example.com|       2024-07-11|       Bronze|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX012|       C107|  20.0|2024-07-16 10:11:00|     USD|192.168.1.17|              10| Grace Hopper|  grace@example.com|       2023-03-22|       Silver|     2024-07-14|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX013|       C108|  10.0|2024-07-16 10:12:00|     USD|192.168.1.18|              10|   Heidi Klum|  heidi@example.com|       2024-07-16|       Bronze|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX014|       C109|  15.0|2024-07-16 10:13:00|     USD|192.168.1.19|              10|   Ivan Drago|   ivan@example.com|       2024-07-16|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","|         TX015|       C999| 100.0|2024-07-16 10:14:00|     USD|192.168.1.20|              10|          NaN|                NaN|             NULL|          NaN|            NaN|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n","+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-------------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["fact table `fact_transactions`, this is our fact table that answers to the business requirement of collecting the transactions. The table have a set of columns similar to this (using a pseudocode):\n","\n","```\n","CREATE TABLE fact_transactions(\n","transaction id, uuid (or integer), primary key\n","timestamp, datetime\n","amount, float\n","customer id, uuid, foreign key\n","fraud flag, boolean)\n","```\n","\n","here we can store all the information about our transactions, then we create 3 dimensional tables to expand the data that we have about customers, timestamp of the transaction and position of the transaction.\n","Using a pseudocode, we will write:\n","\n","```\n","CREATE TABLE dim_customer(\n","customer surrogate key, uuid, primary key\n","customer id, int, foreign key\n","full name, str\n","email, str\n","address, str\n","mobile, str\n","registration date, datetime\n","last login, datetime\n","tier, str\n",")\n","```\n","I would then populate this table using an INSERT INTO and doing schema inference from the data source, so that if the incoming schema does not match with these one we can collect all the transactions no matter what.\n","\n","```\n","CREATE TABLE dim_location(\n","transaction surrogate key, uuid, primary key\n","transaction id, int, foreign key\n","timestamp, datetime, foreign key\n","ip address, str\n","loc x, str\n","loc y, str\n",")\n","```\n","\n","```\n","CREATE TABLE dim_date(\n","transaction surrogate key, uuid, primary key\n","transaction id, int, foreign key\n","timestamp, datetime, foreign key\n","day, str\n","week, str\n","month, str\n","quarter, str\n","year, str\n","day of the week, str\n",")\n","```\n","\n","Even though this table is not required, it is useful so that when we have to query the data filtering them based on the timestamps or dates, we can just join the table and do not have to run particularly complicated operations in our query because we have already unpacked in the table some of the derivates measure such as day of the week.\n","\n","## I did not put any constraint to these table (such as transaction id not null or other primary key values not null) because we are inferring the schema on-read and we enforce it on read (please explain me again if it is correct, i remember that enforcing schema on-read means that when i read i enforce the schema based on a starting schema such the one that I wrote. Am I right? answer at the top of the answer."],"metadata":{"id":"eAtzJM5Y506g"}}]}