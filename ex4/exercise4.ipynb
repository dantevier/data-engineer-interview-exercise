{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zqEc9k7BWUw"
   },
   "source": [
    "### Day 4 Exercise: Data Warehousing, Data Modeling & DevOps/CICD üèóÔ∏è\n",
    "\n",
    "#### Objective\n",
    "This exercise focuses on the principles of data warehousing and analytical data modeling. You will design a Star Schema for our fraud analytics use case and conceptualize how to build and deploy the data pipeline using DevOps and CI/CD practices.\n",
    "\n",
    "#### Scenario\n",
    "The fraud detection rules are now implemented in PySpark. The next step is to store the enriched transaction data and fraud flags in a structured, optimized way for business intelligence (BI) and analytics. You need to design a data model that allows analysts to easily query and build dashboards on fraudulent activities. You also need to think about how to automate the deployment of your data pipeline.\n",
    "\n",
    "#### Data to Use üìä\n",
    "You will use the conceptual output from the Day 3 exercise: a PySpark DataFrame (`sdf_final_transactions`) containing enriched transaction data along with the boolean fraud flags (`is_fraudulent_rule1`, `is_fraudulent_rule2`).\n",
    "\n",
    "---\n",
    "\n",
    "### Part 1: Data Modeling for Fraud Analytics (Conceptual) ‚≠ê\n",
    "\n",
    "#### 1.1 Design a Star Schema\n",
    "Based on the available data, design a **Star Schema** to model the data for analytical querying. Define the tables, columns, data types, and relationships.\n",
    "\n",
    "* **Fact Table**: `fact_transactions`\n",
    "    * What are the measures (the quantitative values) in this table?\n",
    "    * What are the foreign keys that will link to the dimension tables?\n",
    "    * Define all columns, their data types (e.g., INTEGER, DECIMAL, VARCHAR, DATETIME, BOOLEAN), and their purpose.\n",
    "\n",
    "* **Dimension Tables**:\n",
    "    * **`dim_customer`**:\n",
    "        * How would you populate this table?\n",
    "        * Define its columns, including a surrogate key.\n",
    "    * **`dim_date`**:\n",
    "        * Why is a separate date dimension useful?\n",
    "        * What are some useful attributes this table would contain (e.g., day, week, month, quarter, year, day_of_week)?\n",
    "        * Define its columns.\n",
    "    * **`dim_location`** (Optional, but recommended):\n",
    "        * How could you create a location dimension from the `ip_address`? (Conceptually - e.g., using a Geo-IP lookup service).\n",
    "        * What columns would it have?\n",
    "\n",
    "#### 1.2 Slowly Changing Dimensions (SCD)\n",
    "* In Day 2, we discussed SCD Type 2 for `customer_tier`. Now, provide a more detailed explanation.\n",
    "* **Task**: Illustrate how you would update the `dim_customer` table if \"Alice Smith\" (customer_id 'C101') was upgraded from \"Gold\" to \"Platinum\" tier on `2024-07-18`.\n",
    "* Show the state of the `dim_customer` table **before** and **after** the change, including the necessary columns to handle SCD Type 2 (e.g., `customer_sk`, `customer_id`, `tier`, `start_date`, `end_date`, `is_current`).\n",
    "\n",
    "---\n",
    "\n",
    "### Part 2: DevOps & CI/CD for Data Pipelines (Conceptual) ü§ñ\n",
    "\n",
    "#### 2.1 Version Control with Git\n",
    "* Describe how you would structure your project in a Git repository. What would be the key folders and files? (e.g., `/src` for code, `/tests` for unit tests, `/notebooks` for exploration, `requirements.txt`, etc.).\n",
    "* Explain the purpose of a `.gitignore` file in this project. What are some specific files or directories you would add to it?\n",
    "\n",
    "#### 2.2 Continuous Integration (CI)\n",
    "* What is the primary goal of Continuous Integration for this data engineering project?\n",
    "* Describe a simple CI pipeline for your PySpark fraud detection script. What are the key stages or steps?\n",
    "    * **Hint**: Think about what should happen automatically when a developer pushes a change to a feature branch. (e.g., Trigger, Linting, Unit Testing, Packaging).\n",
    "\n",
    "#### 2.3 Continuous Deployment/Delivery (CD)\n",
    "* What is the difference between Continuous Delivery and Continuous Deployment in the context of this project?\n",
    "* Describe a conceptual CD pipeline that takes the tested PySpark application from the CI pipeline and deploys it to your Azure Databricks environment. What are the key stages?\n",
    "    * **Hint**: Think about environments (Dev, Staging, Prod), approvals, and the actual deployment steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOMkgVrO6Clm"
   },
   "source": [
    "SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21435,
     "status": "ok",
     "timestamp": 1752941986233,
     "user": {
      "displayName": "Roberto Cerrone",
      "userId": "14489044185171455121"
     },
     "user_tz": -120
    },
    "id": "j6HkTs6zejng",
    "outputId": "1b56527b-b1aa-418a-ef6e-2392c49aadd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Schema:\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- transaction_hour: integer (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- customer_email: string (nullable = true)\n",
      " |-- registration_date: date (nullable = true)\n",
      " |-- customer_tier: string (nullable = true)\n",
      " |-- last_login_date: string (nullable = true)\n",
      " |-- is_fraudulent_rule1: boolean (nullable = true)\n",
      " |-- timestamp_to_date: date (nullable = true)\n",
      " |-- is_fraudulent_rule1_spark: boolean (nullable = true)\n",
      " |-- prev_ip_address: string (nullable = true)\n",
      " |-- transaction_count_10min: integer (nullable = true)\n",
      " |-- is_fraudulent_rule2: boolean (nullable = true)\n",
      " |-- is_fraudulent_combined: boolean (nullable = true)\n",
      "\n",
      "\n",
      "DataFrame Records:\n",
      "+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-----------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n",
      "|transaction_id|customer_id|amount|          timestamp|currency|  ip_address|transaction_hour|customer_name|   customer_email|registration_date|customer_tier|last_login_date|is_fraudulent_rule1|timestamp_to_date|is_fraudulent_rule1_spark|prev_ip_address|transaction_count_10min|is_fraudulent_rule2|is_fraudulent_combined|\n",
      "+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-----------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n",
      "|         TX001|       C101|150.75|2024-07-16 10:00:00|     USD|192.168.1.10|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX003|       C101| 50.25|2024-07-16 10:02:00|     USD|192.168.1.10|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      2|              false|                 false|\n",
      "|         TX007|       C101|  10.0|2024-07-16 10:06:00|     USD|192.168.1.14|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      3|              false|                 false|\n",
      "|         TX011|       C101| 500.0|2024-07-16 10:10:00|     USD|192.168.1.10|              10|  Alice Smith|alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.14|                      4|               true|                  true|\n",
      "|         TX002|       C102|  25.0|2024-07-16 10:01:30|     USD|192.168.1.11|              10|  Bob Johnson|  bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-----------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"FraudDataLoading\").getOrCreate()\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/data/sdf_final_transaction/part-00000-b3362811-915c-4425-8025-3a497ac441f9-c000.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "# We assume the CSV has a header and infer the schema\n",
    "sdf_final_transactions = spark.read.csv(file_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1752942011644,
     "user": {
      "displayName": "Roberto Cerrone",
      "userId": "14489044185171455121"
     },
     "user_tz": -120
    },
    "id": "j7uDZFRbfE1A",
    "outputId": "84190d70-fdef-4198-c42d-a8edd0557c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Schema:\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- transaction_hour: integer (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- customer_email: string (nullable = true)\n",
      " |-- registration_date: date (nullable = true)\n",
      " |-- customer_tier: string (nullable = true)\n",
      " |-- last_login_date: string (nullable = true)\n",
      " |-- is_fraudulent_rule1: boolean (nullable = true)\n",
      " |-- timestamp_to_date: date (nullable = true)\n",
      " |-- is_fraudulent_rule1_spark: boolean (nullable = true)\n",
      " |-- prev_ip_address: string (nullable = true)\n",
      " |-- transaction_count_10min: integer (nullable = true)\n",
      " |-- is_fraudulent_rule2: boolean (nullable = true)\n",
      " |-- is_fraudulent_combined: boolean (nullable = true)\n",
      "\n",
      "\n",
      "DataFrame Records:\n",
      "+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-------------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n",
      "|transaction_id|customer_id|amount|          timestamp|currency|  ip_address|transaction_hour|customer_name|     customer_email|registration_date|customer_tier|last_login_date|is_fraudulent_rule1|timestamp_to_date|is_fraudulent_rule1_spark|prev_ip_address|transaction_count_10min|is_fraudulent_rule2|is_fraudulent_combined|\n",
      "+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-------------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n",
      "|         TX001|       C101|150.75|2024-07-16 10:00:00|     USD|192.168.1.10|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX003|       C101| 50.25|2024-07-16 10:02:00|     USD|192.168.1.10|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      2|              false|                 false|\n",
      "|         TX007|       C101|  10.0|2024-07-16 10:06:00|     USD|192.168.1.14|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.10|                      3|              false|                 false|\n",
      "|         TX011|       C101| 500.0|2024-07-16 10:10:00|     USD|192.168.1.10|              10|  Alice Smith|  alice@example.com|       2023-01-15|         Gold|     2024-07-15|              false|       2024-07-16|                    false|   192.168.1.14|                      4|               true|                  true|\n",
      "|         TX002|       C102|  25.0|2024-07-16 10:01:30|     USD|192.168.1.11|              10|  Bob Johnson|    bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX005|       C102|  75.5|2024-07-16 10:04:00|     USD|192.168.1.11|              10|  Bob Johnson|    bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|   192.168.1.11|                      2|              false|                 false|\n",
      "|         TX009|       C102| 200.0|2024-07-16 10:08:00|     USD|192.168.1.11|              10|  Bob Johnson|    bob@example.com|       2024-07-09|       Silver|     2024-07-16|              false|       2024-07-16|                    false|   192.168.1.11|                      3|              false|                 false|\n",
      "|         TX004|       C103|1200.0|2024-07-16 10:03:15|     EUR|192.168.1.12|              10|Charlie Brown|charlie@example.com|       2023-11-20|       Bronze|     2024-07-14|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX006|       C104| 300.0|2024-07-16 10:05:00|     USD|192.168.1.13|              10| Diana Prince|  diana@example.com|       2024-07-10|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX008|       C105|   0.0|2024-07-16 10:07:00|     USD|192.168.1.15|              10|    Eve Adams|    eve@example.com|       2023-05-01|         Gold|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX010|       C106|  45.0|2024-07-16 10:09:00|     USD|192.168.1.16|              10|  Frank White|  frank@example.com|       2024-07-11|       Bronze|     2024-07-15|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX012|       C107|  20.0|2024-07-16 10:11:00|     USD|192.168.1.17|              10| Grace Hopper|  grace@example.com|       2023-03-22|       Silver|     2024-07-14|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX013|       C108|  10.0|2024-07-16 10:12:00|     USD|192.168.1.18|              10|   Heidi Klum|  heidi@example.com|       2024-07-16|       Bronze|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX014|       C109|  15.0|2024-07-16 10:13:00|     USD|192.168.1.19|              10|   Ivan Drago|   ivan@example.com|       2024-07-16|       Silver|     2024-07-16|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "|         TX015|       C999| 100.0|2024-07-16 10:14:00|     USD|192.168.1.20|              10|          NaN|                NaN|             NULL|          NaN|            NaN|              false|       2024-07-16|                    false|           NULL|                      1|              false|                 false|\n",
      "+--------------+-----------+------+-------------------+--------+------------+----------------+-------------+-------------------+-----------------+-------------+---------------+-------------------+-----------------+-------------------------+---------------+-----------------------+-------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the schema\n",
    "print(\"DataFrame Schema:\")\n",
    "sdf_final_transactions.printSchema()\n",
    "\n",
    "# Show some records\n",
    "print(\"\\nDataFrame Records:\")\n",
    "sdf_final_transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAtzJM5Y506g"
   },
   "source": [
    "So, I our STAR Schema we shall take in considerations these key aspects:\n",
    "1. we are going to have a fact table, which works as a center of our star\n",
    "2. the fact table will contain as foreign key, the primary keys from the dimensional tables\n",
    "3. we have to set up constraints on the keys as type and nullable\n",
    "\n",
    "Let's start from the fact table and lets consider the transaction table as our fact table\n",
    "\n",
    "\n",
    "note: things to check\n",
    "1. varchar for variables such as ip_address, city, state, long, lat shall be adapted to have an optimized ddl\n",
    "\n",
    "\n",
    "```\n",
    "CREATE TABLE fact_transactions (\n",
    "    transaction_id UUID PRIMARY KEY NOT NULL,\n",
    "    transaction_timestamp TIMESTAMP,\n",
    "    customer_id UUID,\n",
    "    date DATETIME FOREIGN KEY,\n",
    "    location_id INT FOREIGN KEY,\n",
    "    amount FLOAT,\n",
    "    ip_address VARCHAR(100)\n",
    "    fraud_flag BOOLEAN\n",
    ");\n",
    "```\n",
    "\n",
    "As we can see from this schema, we have the primary key and the three foreign keys of the dimensional tables `dim_customer`, `dim_location`, `dim_date`. Lets move on writing the DDL for the location and date table:\n",
    "\n",
    "\n",
    "```\n",
    "CREATE TABLE dim_location (\n",
    "    location_id UUID PRIMARY KEY NOT NULL,\n",
    "    city VARCHAR(50),\n",
    "    state VARCHAR(50),\n",
    "    longitude VARCHAR(50),\n",
    "    latitude VARCHAR(50)\n",
    ");\n",
    "```\n",
    "\n",
    "`dim_location` is a useful table because let us add information thanks to joins instead of performing operations to extract it.\n",
    "PRO: informations that will not change (locations are immutable or so) and easy to query. CON: another table to take in consideration in our DDL.\n",
    "\n",
    "\n",
    "```\n",
    "CREATE TABLE dim_date (\n",
    "    date DATETIME PRIMARY KEY NOT NULL,\n",
    "    day VARCHAR(10),\n",
    "    week VARCHAR(10),\n",
    "    month VARCHAR(10),\n",
    "    quarter VARCHAR(10),\n",
    "    year VARCHAR(10),\n",
    "    day_of_week VARCHAR(10)\n",
    ");\n",
    "```\n",
    "\n",
    "`dim_date` has a similar use as `dim_location` and brings the same PROs and CONs.\n",
    "\n",
    "\n",
    "```\n",
    "CREATE TABLE dim_customer (\n",
    "    customer_sk UUID PRIMARY KEY NOT NULL,\n",
    "    customer_id UUID NOT NULL,\n",
    "    full_name VARCHAR(255),\n",
    "    email VARCHAR(255),\n",
    "    address VARCHAR(255),\n",
    "    mobile VARCHAR(20),\n",
    "    registration_date TIMESTAMP,\n",
    "    last_login TIMESTAMP,\n",
    "    tier VARCHAR(50),\n",
    "    valid_from DATETIME,\n",
    "    valid_to DATETIME,\n",
    "    is_current BOOLEAN\n",
    ");\n",
    "```\n",
    "\n",
    "`dim_customer` is built usign a surrogate key because we are going to run SCD type 2 updates to the table. So it could happen that the same customer (so with a fixed customer_id), might have multiple records so we need a surrogate key to keep track of the new rows. On top of it, having a surrogate key helps us decoupling from the sourcing data and let us manage better the relationships.\n",
    "\n",
    "Lets analyze some key takeaways of this schemas and what shall we take in account:\n",
    "1. varchar for string variables (such as ip_address, city, state, long, lat, mobile, etc.) shall have the right size to have an optimized ddl\n",
    "2. Our fact table relies on `customer_id` for join operations, but it may be that we have multiple records. It is then important to specify which record to pick using `is_current`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhQP1om97KGMTbwwUN5MDu",
   "mount_file_id": "1ZRozoIQh6OjxNTB4vTkI3W5byznzqnmX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
