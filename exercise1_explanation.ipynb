{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"15-7GTKgWxpDkgdPl8MAjil4H8U5VqKVZ","authorship_tag":"ABX9TyMfqzkYe5PHlswS148JOmW6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IK6JU6J_FcZp"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# üöÄ Exercise: Day 1 - Initial Data Ingestion & Cleaning for Fraud Detection üöÄ\n","\n","---\n","\n","**Objective:** This exercise focuses on ingesting and cleaning the foundational data for our fraud detection system using Python and Pandas. You will handle both batch customer data and simulated real-time transaction data, addressing common data quality issues and edge cases.\n","\n","**Scenario:** You are starting to build the \"Real-time Transaction Fraud Detection System.\" Your first task is to reliably ingest customer master data and a batch of simulated transaction events, performing necessary cleaning and preprocessing."],"metadata":{"id":"RM3ZAO_eFqkG"}},{"cell_type":"markdown","source":["## üìù Tasks üìù\n","\n","You'll create two files: `day1_exercise_solution.py` (your Python code) and `day1_exercise_reasoning.md` (your explanations).\n","\n","---\n","\n","### Part 1: `day1_exercise_solution.py` (Python Script)\n","\n","1.  **Data Ingestion:**\n","    * Load the **Customer Master Data CSV string** into a Pandas DataFrame named `df_customers`.\n","    * Parse the **Simulated Transaction Events JSON list** into a Pandas DataFrame named `df_transactions`.\n","    * Print the **first 5 rows** and the `info()` for both DataFrames immediately after ingestion.\n","\n","2.  **Data Cleaning & Preprocessing (`df_customers`):**\n","    * **Handle Missing Values:** Ensure no missing values in critical columns like `customer_id`, `customer_name`, `registration_date`. For this dataset, assume all are present.\n","    * **Correct Data Types:** Convert `registration_date` and `last_login_date` to datetime objects.\n","    * **Handle Duplicates:** Identify and remove any duplicate `customer_id` entries, keeping the first occurrence.\n","\n","3.  **Data Cleaning & Preprocessing (`df_transactions`):**\n","    * **Handle Missing Values:** For the `amount` column, replace \"NULL\" (string) with the median amount of all transactions.\n","    * **Correct Data Types:**\n","        * Ensure `amount` is numeric (float). Handle cases where `amount` might be a string (e.g., \"50.25\").\n","        * Convert `timestamp` to datetime objects.\n","    * **Handle Duplicates:** Identify and remove any duplicate `transaction_id` entries, keeping the first occurrence.\n","    * **Create Derived Column:** Calculate `transaction_hour` (hour of the day, as an integer) from the `timestamp`.\n","\n","4.  **Output:**\n","    * Print the **cleaned `df_customers` info and first 5 rows**.\n","    * Print the **cleaned `df_transactions` info and first 5 rows**.\n","    * Print the **number of unique customers and transactions after cleaning**.\n","\n","---\n","\n","### Part 2: `day1_exercise_reasoning.md` (Markdown File)\n","\n","Explain your reasoning for each step, focusing on the following:\n","\n","1.  **Data Cleaning & Preprocessing Explanations:**\n","    * **Missing Values:** How did you handle missing values in both DataFrames and why did you choose that strategy (e.g., replacement with median, removal)?\n","    * **Data Type Conversion:** Describe your approach to data type conversion for datetime and numeric columns.\n","    * **Duplicate Handling:** Explain your logic for identifying and removing duplicate entries in `customer_id` and `transaction_id`.\n","\n","2.  **Edge Cases & Robustness:**\n","    * **Edge Case 1: Large Data Simulation:**\n","        Imagine the Simulated Transaction Events list contains millions of entries and cannot be loaded into memory all at once. Describe conceptually how you would handle this scenario (e.g., using Dask, processing in chunks, or a distributed framework like Spark). You don't need to implement this, but explain your approach.\n","    * **Edge Case 2: Inconsistent Data Formats:**\n","        What if the `amount` occasionally comes with currency symbols (e.g., \"$150.75\") or uses a comma as a decimal separator (e.g., \"150,75\")? Describe how you would make your parsing more robust.\n","        Implement a basic version of this for the currency symbol in your Python script (e.g., remove \"$\").\n","    * **Edge Case 3: Schema Drift/Unexpected Columns:**\n","        What if a new column like `payment_processor` suddenly appears in some transaction events, or an expected column like `currency` is sometimes missing? Describe how you would handle such schema variations in a production ETL pipeline (e.g., flexible schema, error logging, schema evolution tools).\n","\n","3.  **Assumptions:**\n","\n","    List any assumptions you made while performing the data ingestion and cleaning."],"metadata":{"id":"hzdSsR5aFt0i"}},{"cell_type":"markdown","source":["---\n","\n","## Data to Use:\n","\n","### Customer Master Data (CSV String):\n","\n","```csv\n","customer_id,customer_name,customer_email,registration_date,customer_tier,last_login_date\n","C101,Alice Smith,alice@example.com,2023-01-15,Gold,2024-07-15\n","C102,Bob Johnson,bob@example.com,2024-07-09,Silver,2024-07-16\n","C103,Charlie Brown,charlie@example.com,2023-11-20,Bronze,2024-07-14\n","C104,Diana Prince,diana@example.com,2024-07-10,Silver,2024-07-16\n","C105,Eve Adams,eve@example.com,2023-05-01,Gold,2024-07-15\n","C106,Frank White,frank@example.com,2024-07-11,Bronze,2024-07-15\n","C107,Grace Hopper,grace@example.com,2023-03-22,Silver,2024-07-14\n","C108,Heidi Klum,heidi@example.com,2024-07-16,Bronze,2024-07-16\n","C109,Ivan Drago,ivan@example.com,2024-07-16,Silver,2024-07-16\n","```\n","---\n","\n","### Simulated Transaction Events (List of JSON Strings):\n","\n","```json\n","[\n","    {\"transaction_id\": \"TX001\", \"customer_id\": \"C101\", \"amount\": 150.75, \"timestamp\": \"2024-07-16 10:00:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.10\"},\n","    {\"transaction_id\": \"TX002\", \"customer_id\": \"C102\", \"amount\": 25.00, \"timestamp\": \"2024-07-16 10:01:30\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.11\"},\n","    {\"transaction_id\": \"TX003\", \"customer_id\": \"C101\", \"amount\": \"50.25\", \"timestamp\": \"2024-07-16 10:02:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.10\"},\n","    {\"transaction_id\": \"TX004\", \"customer_id\": \"C103\", \"amount\": 1200.00, \"timestamp\": \"2024-07-16 10:03:15\", \"currency\": \"EUR\", \"ip_address\": \"192.168.1.12\"},\n","    {\"transaction_id\": \"TX005\", \"customer_id\": \"C102\", \"amount\": \"75.50\", \"timestamp\": \"2024-07-16 10:04:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.11\"},\n","    {\"transaction_id\": \"TX006\", \"customer_id\": \"C104\", \"amount\": 300.00, \"timestamp\": \"2024-07-16 10:05:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.13\"},\n","    {\"transaction_id\": \"TX007\", \"customer_id\": \"C101\", \"amount\": 10.00, \"timestamp\": \"2024-07-16 10:06:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.14\"},\n","    {\"transaction_id\": \"TX008\", \"customer_id\": \"C105\", \"amount\": \"NULL\", \"timestamp\": \"2024-07-16 10:07:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.15\"},\n","    {\"transaction_id\": \"TX009\", \"customer_id\": \"C102\", \"amount\": 200.00, \"timestamp\": \"2024-07-16 10:08:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.11\"},\n","    {\"transaction_id\": \"TX010\", \"customer_id\": \"C106\", \"amount\": 45.00, \"timestamp\": \"2024-07-16 10:09:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.16\"},\n","    {\"transaction_id\": \"TX011\", \"customer_id\": \"C101\", \"amount\": 500.00, \"timestamp\": \"2024-07-16 10:10:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.10\"},\n","    {\"transaction_id\": \"TX012\", \"customer_id\": \"C107\", \"amount\": 20.00, \"timestamp\": \"2024-07-16 10:11:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.17\"},\n","    {\"transaction_id\": \"TX013\", \"customer_id\": \"C108\", \"amount\": 10.00, \"timestamp\": \"2024-07-16 10:12:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.18\"},\n","    {\"transaction_id\": \"TX014\", \"customer_id\": \"C109\", \"amount\": 15.00, \"timestamp\": \"2024-07-16 10:13:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.19\"},\n","    {\"transaction_id\": \"TX015\", \"customer_id\": \"C999\", \"amount\": 100.00, \"timestamp\": \"2024-07-16 10:14:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.20\"},\n","    {\"transaction_id\": \"TX001\", \"customer_id\": \"C101\", \"amount\": 150.75, \"timestamp\": \"2024-07-16 10:00:00\", \"currency\": \"USD\", \"ip_address\": \"192.168.1.10\"}\n","]\n","```"],"metadata":{"id":"g_iX5oRSG5YC"}}]}